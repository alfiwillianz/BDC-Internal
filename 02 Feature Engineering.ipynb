{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c298e8",
   "metadata": {},
   "source": [
    "# Essay Scoring Model - CatBoost with Sentence Transformers\n",
    "\n",
    "This notebook implements an automated essay scoring system using:\n",
    "- **Qwen3-Embedding-8B** for text embeddings \n",
    "- **CatBoost** with **MultiRMSEWithMissingValues** loss function for multi-target regression on 4 scoring dimensions:\n",
    "  - Task Achievement\n",
    "  - Coherence and Cohesion  \n",
    "  - Lexical Resource\n",
    "  - Grammatical Range\n",
    "\n",
    "**Key Advantage**: CatBoost's MultiRMSEWithMissingValues allows us to handle missing target values without dropping data samples.\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for essay scoring feature engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Iterable\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# NLP and text processing libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import textstat\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import BitsAndBytesConfig\n",
    "from pyspellchecker import SpellChecker\n",
    "import language_tool_python\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Configuration constants\n",
    "EMBEDDING_MODEL = \"Alibaba-NLP/gte-Qwen2-7B-instruct\"  # Main embedding model\n",
    "FEATURE_EMBEDDING_MODEL = \"BAAI/bge-large-en-v1.5\"     # For similarity features\n",
    "BATCH_SIZE = 16  # Optimized batch size\n",
    "EMBEDDING_SUB_BATCH = 16\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a8a53",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Load the training and test datasets containing essays with their prompts and scoring rubrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6652b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test datasets\n",
    "train = pd.read_csv('df_train.csv')\n",
    "test = pd.read_csv('df_test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train.shape}\")\n",
    "print(f\"Test data shape: {test.shape}\")\n",
    "print(f\"\\nTraining columns: {list(train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa83c9",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Clean and prepare the text data for embedding generation. This includes:\n",
    "- Removing escape characters and newlines\n",
    "- Normalizing whitespace\n",
    "- Converting to lowercase\n",
    "- Combining prompt and essay text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text_series):\n",
    "    \"\"\"\n",
    "    Clean text data by removing escape characters, normalizing whitespace, and converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "        text_series (pd.Series): Series containing text data to clean\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Cleaned text data\n",
    "    \"\"\"\n",
    "    return (\n",
    "        text_series\n",
    "        .str.replace(r'\\\\[nrt]|\\n|\\r|\\t', ' ', regex=True)  # Remove literal and real escape chars\n",
    "        .str.replace(r'\\s+', ' ', regex=True)               # Collapse multiple spaces\n",
    "        .str.strip()                                        # Remove leading/trailing spaces\n",
    "        .str.lower()                                        # Convert to lowercase\n",
    "    )\n",
    "\n",
    "# Clean text data for training and test sets\n",
    "print(\"Cleaning training data...\")\n",
    "train['essay_clean'] = clean_text(train['essay'])\n",
    "train['prompt_clean'] = clean_text(train['prompt'])\n",
    "\n",
    "print(\"Cleaning test data...\")\n",
    "test['essay_clean'] = clean_text(test['essay'])\n",
    "test['prompt_clean'] = clean_text(test['prompt'])\n",
    "\n",
    "print(\"Text cleaning completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a sample of cleaned essay text\n",
    "print(\"Sample cleaned essay (first 200 characters):\")\n",
    "print(train['essay_clean'][0][:200] + \"...\" if len(train['essay_clean'][0]) > 200 else train['essay_clean'][0])\n",
    "\n",
    "print(f\"\\nOriginal length: {len(train['essay'][0])} characters\")\n",
    "print(f\"Cleaned length: {len(train['essay_clean'][0])} characters\")\n",
    "\n",
    "# Now I need to search for cells that contain the feature engineering section to complete the variables\n",
    "# Let me first create the train_with_features and test_with_features that should be train_clean and test_clean\n",
    "\n",
    "# Since we need features for the model, let's create the feature engineering for train_clean and test_clean\n",
    "print(\"Running comprehensive feature engineering...\")\n",
    "\n",
    "# Feature engineering will be done in the next cells\n",
    "print(\"Feature engineering setup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine prompt and essay text with separator token\n",
    "# [SEP] token helps the model distinguish between prompt and essay content\n",
    "print(\"Merging prompt and essay text...\")\n",
    "train['merged_text'] = train['prompt_clean'] + ' [SEP] ' + train['essay_clean']\n",
    "test['merged_text'] = test['prompt_clean'] + ' [SEP] ' + test['essay_clean']\n",
    "\n",
    "print(f\"Average merged text length: {train['merged_text'].str.len().mean():.0f} characters\")\n",
    "print(\"Text merging completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of merged text to verify format\n",
    "sample_text = str(train['merged_text'][0])\n",
    "print(\"Sample merged text (first 300 characters):\")\n",
    "print(sample_text[:300] + \"...\" if len(sample_text) > 300 else sample_text)\n",
    "\n",
    "# Find the [SEP] token position to verify structure\n",
    "sep_pos = sample_text.find('[SEP]')\n",
    "print(f\"\\n[SEP] token found at position: {sep_pos}\")\n",
    "print(f\"Prompt portion length: {sep_pos} characters\")\n",
    "print(f\"Essay portion length: {len(sample_text) - sep_pos - 6} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca80313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all data - CatBoost can handle missing target values\n",
    "print(\"Data preparation for CatBoost with missing value support:\")\n",
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Test samples: {len(test)}\")\n",
    "\n",
    "# Only remove rows where essential text data is missing\n",
    "train_clean = train.dropna(subset=['essay', 'prompt'])\n",
    "test_clean = test.dropna(subset=['essay', 'prompt'])\n",
    "\n",
    "print(f\"\\nAfter removing rows with missing text data:\")\n",
    "print(f\"Training samples: {len(train_clean)} (removed {len(train) - len(train_clean)} due to missing text)\")\n",
    "print(f\"Test samples: {len(test_clean)} (removed {len(test) - len(test_clean)} due to missing text)\")\n",
    "\n",
    "# Check missing values in target variables (these are OK for CatBoost)\n",
    "scoring_dimensions = ['task_achievement', 'coherence_and_cohesion', 'lexical_resource', 'grammatical_range']\n",
    "missing_targets = train_clean[scoring_dimensions].isnull().sum()\n",
    "print(f\"\\nMissing target values (will be handled by CatBoost):\")\n",
    "for dim, missing_count in missing_targets.items():\n",
    "    print(f\"  {dim}: {missing_count} missing values ({missing_count/len(train_clean)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal samples retained for training: {len(train_clean)}\")\n",
    "print(\"CatBoost MultiRMSEWithMissingValues will handle missing targets automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f98c12",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering\n",
    "\n",
    "Extract comprehensive linguistic and textual features including:\n",
    "- **Lexical Features**: Word count, vocabulary diversity, readability scores\n",
    "- **Syntactic Features**: POS distribution, clause complexity, sentence structure\n",
    "- **Semantic Features**: Prompt-essay similarity, topic coverage, named entity analysis\n",
    "- **Stylistic Features**: Punctuation patterns, capitalization, grammar/spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Feature Engineering Implementation\n",
    "# =========================================================\n",
    "\n",
    "# =================================================================\n",
    "# CORE FEATURE ENGINEERING SETUP\n",
    "# =================================================================\n",
    "\n",
    "# Global variables for text processing\n",
    "TOKEN_RE = re.compile(r\"\\b\\w+\\b\")\n",
    "PUNCTUATION = set(string.punctuation)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "SPELL = SpellChecker()\n",
    "\n",
    "# Initialize LanguageTool for grammar checking\n",
    "print(\"Initializing LanguageTool for grammar checking...\")\n",
    "try:\n",
    "    _TOOL = language_tool_python.LanguageTool('en-US')\n",
    "    print(\"✓ LanguageTool initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  LanguageTool initialization failed: {e}\")\n",
    "    _TOOL = None\n",
    "\n",
    "# Global spaCy model (lazy-loaded)\n",
    "_SPACY_NLP = None\n",
    "\n",
    "def clear_vram(*objs):\n",
    "    \"\"\"Clear GPU memory and Python objects for memory management\"\"\"\n",
    "    for o in objs:\n",
    "        try:\n",
    "            del o\n",
    "        except Exception:\n",
    "            pass\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Extract word tokens from text\"\"\"\n",
    "    return TOKEN_RE.findall((text or \"\").lower())\n",
    "\n",
    "def count_spelling_errors(text: str) -> int:\n",
    "    \"\"\"Count misspelled words in text\"\"\"\n",
    "    return len(SPELL.unknown(tokenize(text)))\n",
    "\n",
    "def count_sentences(text: str) -> int:\n",
    "    \"\"\"Count sentences in text using NLTK\"\"\"\n",
    "    try:\n",
    "        return len(nltk.sent_tokenize(text or \"\"))\n",
    "    except Exception:\n",
    "        # Fallback: count sentence-ending punctuation\n",
    "        return (text or \"\").count(\".\") + (text or \"\").count(\"!\") + (text or \"\").count(\"?\")\n",
    "\n",
    "def count_stopwords(text: str) -> int:\n",
    "    \"\"\"Count stopwords in text\"\"\"\n",
    "    return sum(1 for w in (text or \"\").split() if w.lower() in STOPWORDS)\n",
    "\n",
    "def prompt_overlap(prompt: str, essay: str) -> int:\n",
    "    \"\"\"Count overlapping words between prompt and essay\"\"\"\n",
    "    prompt_words = set((prompt or \"\").lower().split())\n",
    "    essay_words = set((essay or \"\").lower().split())\n",
    "    return len(prompt_words.intersection(essay_words))\n",
    "\n",
    "def grammar_error_count(text: str) -> int:\n",
    "    \"\"\"Count grammar errors using LanguageTool with timeout handling\"\"\"\n",
    "    try:\n",
    "        # Limit text length to prevent timeouts\n",
    "        text_to_check = (text or \"\")[:5000]  # Limit to 5000 chars\n",
    "        if not text_to_check.strip():\n",
    "            return 0\n",
    "        \n",
    "        # Use a shorter timeout to prevent hanging\n",
    "        matches = _TOOL.check(text_to_check)\n",
    "        return len(matches)\n",
    "    except Exception:\n",
    "        # Return 0 if LanguageTool fails (better than crashing)\n",
    "        return 0\n",
    "\n",
    "print(\"✓ Feature engineering setup completed successfully\")\n",
    "print(\"All advanced NLP tools are active and ready!\")\n",
    "\n",
    "# =========================================================\n",
    "# EMBEDDING GENERATION OPTIMIZED FOR A100 80GB\n",
    "# =========================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# A100-optimized quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "print(f\"Loading embedding model: {EMBEDDING_MODEL}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Initialize sentence transformer with A100 optimizations\n",
    "embedding_model = SentenceTransformer(\n",
    "    EMBEDDING_MODEL,\n",
    "    device=device,\n",
    "    trust_remote_code=True,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.bfloat16,\n",
    "        \"quantization_config\": quantization_config\n",
    "    }\n",
    ")\n",
    "\n",
    "# Enable A100-specific optimizations\n",
    "if hasattr(torch.nn.functional, 'scaled_dot_product_attention'):\n",
    "    print(\"Flash Attention available - enabled for optimal performance\")\n",
    "\n",
    "def encode_in_batches_a100(model, texts, batch_size=BATCH_SIZE, device='cuda'):\n",
    "    \"\"\"\n",
    "    A100-optimized batch encoding with memory management and performance optimizations.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Pre-allocate memory for better performance\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=f\"Encoding batches (size={batch_size})\"):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            \n",
    "            # Use optimized encoding with mixed precision\n",
    "            batch_emb = model.encode(\n",
    "                batch, \n",
    "                batch_size=len(batch),\n",
    "                show_progress_bar=False, \n",
    "                device=device,\n",
    "                convert_to_tensor=True,\n",
    "                normalize_embeddings=True  # Normalize for better similarity computation\n",
    "            )\n",
    "            \n",
    "            embeddings.append(batch_emb.cpu().half())  # Use half precision for memory efficiency\n",
    "            \n",
    "            # Efficient memory cleanup every few batches\n",
    "            if (i // batch_size + 1) % 5 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "    # Final memory cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.vstack([emb.numpy() for emb in embeddings])\n",
    "\n",
    "# Generate embeddings for training data with A100 optimization\n",
    "print(f\"\\nGenerating deep embeddings for {len(train_clean)} training samples...\")\n",
    "print(f\"Using optimized batch size: {BATCH_SIZE} (A100 optimized)\")\n",
    "\n",
    "train_embeddings = encode_in_batches_a100(\n",
    "    embedding_model, \n",
    "    train_clean['merged_text'].tolist(), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Generate embeddings for test data\n",
    "print(f\"Generating deep embeddings for {len(test_clean)} test samples...\")\n",
    "test_embeddings = encode_in_batches_a100(\n",
    "    embedding_model, \n",
    "    test_clean['merged_text'].tolist(), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Performance analysis\n",
    "print(f\"\\nEmbedding generation completed with A100 optimizations:\")\n",
    "print(f\"Training embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Test embeddings: {test_embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {train_embeddings.shape[1]}\")\n",
    "print(f\"Memory usage optimized with half precision and batch processing\")\n",
    "\n",
    "# Verify data integrity\n",
    "nan_train = np.isnan(train_embeddings).sum()\n",
    "nan_test = np.isnan(test_embeddings).sum()\n",
    "print(f\"Data integrity check - NaN values: Train={nan_train}, Test={nan_test}\")\n",
    "\n",
    "# Clean up GPU memory\n",
    "del embedding_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Deep embedding generation optimized for A100 completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e72147f",
   "metadata": {},
   "source": [
    "## Basic Text Processing Functions\n",
    "\n",
    "These fundamental text processing functions extract basic linguistic features from essays:\n",
    "\n",
    "### Why These Features Matter for Essay Scoring:\n",
    "\n",
    "1. **Tokenization & Word Counting**: Essential for measuring essay length and complexity\n",
    "2. **Sentence Detection**: Helps assess structural organization and coherence\n",
    "3. **Spelling & Grammar Error Detection**: Direct indicators of language proficiency\n",
    "4. **Stopword Analysis**: Balance between content words and function words\n",
    "5. **Prompt-Essay Overlap**: Measures how well the essay addresses the given prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract word tokens from text using regex pattern.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        List of lowercase word tokens\n",
    "    \"\"\"\n",
    "    return TOKEN_RE.findall((text or \"\").lower())\n",
    "\n",
    "def count_sentences(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Count sentences in text using NLTK sentence tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Number of sentences (fallback to punctuation counting if NLTK fails)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(nltk.sent_tokenize(text or \"\"))\n",
    "    except Exception:\n",
    "        # Fallback: count sentence-ending punctuation\n",
    "        return (text or \"\").count(\".\") + (text or \"\").count(\"!\") + (text or \"\").count(\"?\")\n",
    "\n",
    "def count_spelling_errors(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Count misspelled words using PySpellChecker.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Number of misspelled words\n",
    "    \"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    unknown_words = SPELL.unknown(tokens)\n",
    "    return len(unknown_words)\n",
    "\n",
    "def count_stopwords(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Count stopwords (common function words) in text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Number of stopwords\n",
    "    \"\"\"\n",
    "    return sum(1 for word in (text or \"\").split() if word.lower() in STOPWORDS)\n",
    "\n",
    "def prompt_overlap(prompt: str, essay: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculate word overlap between prompt and essay.\n",
    "    Measures how well the essay addresses the prompt topic.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The essay prompt text\n",
    "        essay: The student's essay text\n",
    "        \n",
    "    Returns:\n",
    "        Number of overlapping words between prompt and essay\n",
    "    \"\"\"\n",
    "    prompt_words = set((prompt or \"\").lower().split())\n",
    "    essay_words = set((essay or \"\").lower().split())\n",
    "    return len(prompt_words.intersection(essay_words))\n",
    "\n",
    "def grammar_error_count(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Count grammar errors using LanguageTool with timeout handling.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Number of grammar errors (0 if LanguageTool fails)\n",
    "    \"\"\"\n",
    "    if not _TOOL:\n",
    "        return 0\n",
    "        \n",
    "    try:\n",
    "        # Limit text length to prevent timeouts\n",
    "        text_to_check = (text or \"\")[:5000]  # Limit to 5000 chars\n",
    "        if not text_to_check.strip():\n",
    "            return 0\n",
    "        \n",
    "        matches = _TOOL.check(text_to_check)\n",
    "        return len(matches)\n",
    "    except Exception:\n",
    "        # Return 0 if LanguageTool fails (better than crashing)\n",
    "        return 0\n",
    "\n",
    "print(\"✓ Basic text processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c85b2c",
   "metadata": {},
   "source": [
    "## Advanced NLP Features with spaCy\n",
    "\n",
    "These advanced features use spaCy's linguistic analysis capabilities to extract sophisticated features that correlate with essay quality:\n",
    "\n",
    "### Why These Features Are Important:\n",
    "\n",
    "1. **Capitalization Features**: \n",
    "   - Proper capitalization indicates writing maturity\n",
    "   - Proper nouns show specific knowledge and detail\n",
    "\n",
    "2. **Part-of-Speech Distribution**:\n",
    "   - Noun ratio: Content density and concrete thinking\n",
    "   - Verb ratio: Action and dynamic writing\n",
    "   - Adjective ratio: Descriptive language quality\n",
    "   - Adverb ratio: Modification and nuance\n",
    "\n",
    "3. **Syntactic Complexity**:\n",
    "   - Clause complexity: Sophisticated sentence structures\n",
    "   - Shows advanced grammatical knowledge\n",
    "\n",
    "4. **Named Entity Analysis**:\n",
    "   - Entity overlap with prompt: Topic relevance\n",
    "   - Entity count: Specificity and detail level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# spaCy-based linguistic features\n",
    "# -------------------------\n",
    "\n",
    "def _get_nlp():\n",
    "    \"\"\"\n",
    "    Lazy-load spaCy model for memory efficiency.\n",
    "    \n",
    "    Returns:\n",
    "        Loaded spaCy English model\n",
    "    \"\"\"\n",
    "    global _SPACY_NLP\n",
    "    if _SPACY_NLP is None:\n",
    "        print(\"Loading spaCy model...\")\n",
    "        try:\n",
    "            _SPACY_NLP = spacy.load(\"en_core_web_sm\")\n",
    "            print(\"✓ spaCy model loaded successfully\")\n",
    "        except OSError:\n",
    "            print(\"⚠️  spaCy model 'en_core_web_sm' not found. Please install it with:\")\n",
    "            print(\"python -m spacy download en_core_web_sm\")\n",
    "            return None\n",
    "    return _SPACY_NLP\n",
    "\n",
    "def capitalization_features(doc) -> dict:\n",
    "    \"\"\"\n",
    "    Extract capitalization patterns from spaCy document.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy processed document\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with capitalization metrics\n",
    "    \"\"\"\n",
    "    alpha_tokens = [token for token in doc if token.is_alpha]\n",
    "    word_count = len(alpha_tokens) or 1  # Avoid division by zero\n",
    "    \n",
    "    cap_words = sum(1 for token in alpha_tokens \n",
    "                   if token.text and token.text[0].isupper())\n",
    "    proper_nouns = sum(1 for token in doc if token.pos_ == \"PROPN\")\n",
    "    \n",
    "    return {\n",
    "        \"capitalized_word_count\": cap_words,\n",
    "        \"proper_noun_count\": proper_nouns,\n",
    "        \"capitalized_word_ratio\": cap_words / word_count,\n",
    "        \"proper_noun_ratio\": proper_nouns / word_count\n",
    "    }\n",
    "\n",
    "def pos_distribution(doc) -> dict:\n",
    "    \"\"\"\n",
    "    Extract part-of-speech distribution from spaCy document.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy processed document\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with POS ratios\n",
    "    \"\"\"\n",
    "    alpha_tokens = [token for token in doc if token.is_alpha]\n",
    "    word_count = len(alpha_tokens) or 1\n",
    "    pos_counts = Counter(token.pos_ for token in doc)\n",
    "    \n",
    "    return {\n",
    "        \"noun_ratio\": pos_counts.get(\"NOUN\", 0) / word_count,\n",
    "        \"verb_ratio\": pos_counts.get(\"VERB\", 0) / word_count,\n",
    "        \"adj_ratio\": pos_counts.get(\"ADJ\", 0) / word_count,\n",
    "        \"adv_ratio\": pos_counts.get(\"ADV\", 0) / word_count\n",
    "    }\n",
    "\n",
    "def clause_complexity(doc) -> float:\n",
    "    \"\"\"\n",
    "    Calculate syntactic complexity as clauses per sentence.\n",
    "    Higher values indicate more complex sentence structures.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy processed document\n",
    "        \n",
    "    Returns:\n",
    "        Average clauses per sentence\n",
    "    \"\"\"\n",
    "    sentences = list(doc.sents)\n",
    "    if not sentences:\n",
    "        return 0.0\n",
    "    \n",
    "    # Dependencies that indicate clauses\n",
    "    clause_dependencies = {\"csubj\", \"ccomp\", \"xcomp\", \"advcl\", \"relcl\"}\n",
    "    clause_count = sum(1 for token in doc if token.dep_ in clause_dependencies)\n",
    "    \n",
    "    return clause_count / len(sentences)\n",
    "\n",
    "def named_entity_features(prompt_doc, essay_doc) -> dict:\n",
    "    \"\"\"\n",
    "    Extract named entity overlap between prompt and essay.\n",
    "    Measures topic relevance and specificity.\n",
    "    \n",
    "    Args:\n",
    "        prompt_doc: spaCy processed prompt document\n",
    "        essay_doc: spaCy processed essay document\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with named entity metrics\n",
    "    \"\"\"\n",
    "    essay_entities = set((ent.text.lower(), ent.label_) for ent in essay_doc.ents)\n",
    "    prompt_entities = set((ent.text.lower(), ent.label_) for ent in prompt_doc.ents)\n",
    "    overlapping_entities = essay_entities & prompt_entities\n",
    "    \n",
    "    return {\n",
    "        \"ner_count\": len(essay_entities),\n",
    "        \"ner_overlap_count\": len(overlapping_entities),\n",
    "        \"ner_overlap_ratio\": (len(overlapping_entities) / len(prompt_entities)) if prompt_entities else 0.0\n",
    "    }\n",
    "\n",
    "print(\"✓ Advanced spaCy-based linguistic features defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Readability and stylistic features\n",
    "# -------------------------\n",
    "\n",
    "def topic_coverage(prompt: str, essay: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate what fraction of prompt keywords appear in the essay.\n",
    "    Higher values indicate better prompt adherence.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The essay prompt text\n",
    "        essay: The student's essay text\n",
    "        \n",
    "    Returns:\n",
    "        Ratio of prompt keywords covered in the essay (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    prompt_keywords = set(tokenize(prompt))\n",
    "    if not prompt_keywords:\n",
    "        return 0.0\n",
    "    essay_words = set(tokenize(essay))\n",
    "    return len(prompt_keywords & essay_words) / len(prompt_keywords)\n",
    "\n",
    "def punctuation_features(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract punctuation usage patterns as indicators of writing sophistication.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with punctuation metrics\n",
    "    \"\"\"\n",
    "    punctuation_counts = Counter(char for char in (text or \"\") if char in PUNCTUATION)\n",
    "    total_punctuation = sum(punctuation_counts.values())\n",
    "    word_count = len(tokenize(text)) or 1\n",
    "    \n",
    "    return {\n",
    "        \"comma_count\": punctuation_counts.get(\",\", 0),\n",
    "        \"period_count\": punctuation_counts.get(\".\", 0),\n",
    "        \"question_count\": punctuation_counts.get(\"?\", 0),\n",
    "        \"exclam_count\": punctuation_counts.get(\"!\", 0),\n",
    "        \"punctuation_ratio\": total_punctuation / word_count\n",
    "    }\n",
    "\n",
    "def syllables_per_word(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate average syllables per word as a complexity metric.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Average syllables per word\n",
    "    \"\"\"\n",
    "    words = tokenize(text)\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    total_syllables = sum(textstat.syllable_count(word) for word in words)\n",
    "    return total_syllables / len(words)\n",
    "\n",
    "def readability_scores(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate multiple readability metrics using textstat library.\n",
    "    \n",
    "    Why these metrics matter:\n",
    "    - Flesch Reading Ease: Higher scores = easier to read\n",
    "    - Flesch-Kincaid Grade: Grade level required to understand text\n",
    "    - Dale-Chall Score: Difficulty based on familiar words\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with readability scores\n",
    "    \"\"\"\n",
    "    text = text or \"\"\n",
    "    \n",
    "    def safe_metric(metric_func, default=0.0):\n",
    "        \"\"\"Safely compute metric with fallback\"\"\"\n",
    "        try:\n",
    "            return float(metric_func(text))\n",
    "        except Exception:\n",
    "            return default\n",
    "    \n",
    "    return {\n",
    "        \"flesch_reading_ease\": safe_metric(textstat.flesch_reading_ease, 0.0),\n",
    "        \"flesch_kincaid_grade\": safe_metric(textstat.flesch_kincaid_grade, 0.0),\n",
    "        \"dale_chall_score\": safe_metric(textstat.dale_chall_readability_score, 0.0),\n",
    "    }\n",
    "\n",
    "print(\"✓ Readability and stylistic feature functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410da78",
   "metadata": {},
   "source": [
    "## Readability and Stylistic Features\n",
    "\n",
    "These features measure the sophistication and accessibility of the writing:\n",
    "\n",
    "### Why These Features Matter:\n",
    "\n",
    "1. **Topic Coverage**: \n",
    "   - Measures prompt adherence (key scoring criterion)\n",
    "   - Shows how well the essay addresses the given task\n",
    "\n",
    "2. **Punctuation Analysis**:\n",
    "   - Comma usage: Sentence complexity and proper grammar\n",
    "   - Question/exclamation marks: Rhetorical sophistication\n",
    "   - Overall punctuation ratio: Writing mechanics proficiency\n",
    "\n",
    "3. **Syllable Complexity**:\n",
    "   - Average syllables per word: Vocabulary sophistication\n",
    "   - Correlates with lexical resource scoring dimension\n",
    "\n",
    "4. **Readability Metrics**:\n",
    "   - **Flesch Reading Ease**: Sentence length and syllable complexity balance\n",
    "   - **Flesch-Kincaid Grade**: Appropriate complexity for target audience  \n",
    "   - **Dale-Chall Score**: Vocabulary difficulty assessment\n",
    "\n",
    "These metrics help evaluate both the **Lexical Resource** and **Grammatical Range** scoring dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70afda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Embedding utilities optimized for A100 80GB\n",
    "# -------------------------\n",
    "\n",
    "def chunked_iterable(iterable: Iterable, chunk_size: int):\n",
    "    \"\"\"\n",
    "    Split iterable into chunks for efficient batch processing.\n",
    "    \n",
    "    Args:\n",
    "        iterable: Input iterable to chunk\n",
    "        chunk_size: Size of each chunk\n",
    "        \n",
    "    Yields:\n",
    "        Chunks of the iterable\n",
    "    \"\"\"\n",
    "    iterable_list = list(iterable)\n",
    "    for i in range(0, len(iterable_list), chunk_size):\n",
    "        yield iterable_list[i:i+chunk_size]\n",
    "\n",
    "def _load_sentence_transformer(model_name: str, device: torch.device, use_fp16: bool = True) -> SentenceTransformer:\n",
    "    \"\"\"\n",
    "    Load sentence transformer model with GPU optimizations.\n",
    "    \n",
    "    Args:\n",
    "        model_name: HuggingFace model name\n",
    "        device: Torch device to use\n",
    "        use_fp16: Whether to use half-precision for memory efficiency\n",
    "        \n",
    "    Returns:\n",
    "        Loaded SentenceTransformer model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name, device=device)\n",
    "        print(f\"✓ Successfully loaded model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        fallback_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        print(f\"⚠️  Model loading failed: {e}\")\n",
    "        print(f\"Using fallback model: {fallback_model}\")\n",
    "        model = SentenceTransformer(fallback_model, device=device)\n",
    "    \n",
    "    # GPU precision optimization\n",
    "    if use_fp16 and device.type == \"cuda\":\n",
    "        try:\n",
    "            model.half()\n",
    "            print(\"✓ Model converted to FP16 for memory optimization\")\n",
    "        except Exception:\n",
    "            print(\"⚠️  FP16 conversion failed - using default precision\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def encode_with_model_once(texts: List[str],\n",
    "                          model_name: str = \"BAAI/bge-large-en-v1.5\",\n",
    "                          sub_batch_size: int = 32,\n",
    "                          device: torch.device = device,\n",
    "                          move_to_cpu: bool = True,\n",
    "                          use_fp16: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode texts using sentence transformer with efficient memory management.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of texts to encode\n",
    "        model_name: HuggingFace model name\n",
    "        sub_batch_size: Batch size for encoding\n",
    "        device: Device to use for computation\n",
    "        move_to_cpu: Whether to move results to CPU for memory efficiency\n",
    "        use_fp16: Whether to use half-precision\n",
    "        \n",
    "    Returns:\n",
    "        Tensor of encoded embeddings\n",
    "    \"\"\"\n",
    "    model = _load_sentence_transformer(model_name, device=device, use_fp16=use_fp16)\n",
    "    all_embeddings: List[torch.Tensor] = []\n",
    "    \n",
    "    total_chunks = len(list(chunked_iterable(texts, sub_batch_size)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=use_fp16):\n",
    "            for i, sub_batch in enumerate(tqdm(\n",
    "                chunked_iterable(texts, sub_batch_size),\n",
    "                desc=f\"Encoding {len(texts):,} texts ({sub_batch_size} per batch)\",\n",
    "                total=total_chunks\n",
    "            )):\n",
    "                embeddings = model.encode(\n",
    "                    sub_batch, \n",
    "                    batch_size=len(sub_batch),\n",
    "                    convert_to_tensor=True, \n",
    "                    device=device, \n",
    "                    show_progress_bar=False,\n",
    "                    normalize_embeddings=True\n",
    "                )\n",
    "                \n",
    "                if move_to_cpu:\n",
    "                    all_embeddings.append(embeddings.cpu())\n",
    "                    del embeddings\n",
    "                    # Periodic memory cleanup\n",
    "                    if (i + 1) % 8 == 0:\n",
    "                        clear_vram()\n",
    "                else:\n",
    "                    all_embeddings.append(embeddings)\n",
    "    \n",
    "    # Clean up model memory\n",
    "    del model\n",
    "    clear_vram()\n",
    "    \n",
    "    return torch.cat(all_embeddings, dim=0) if all_embeddings else torch.empty((0, 0))\n",
    "\n",
    "print(\"✓ GPU-optimized embedding utilities configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5d9ce",
   "metadata": {},
   "source": [
    "## Embedding Utilities for Semantic Features\n",
    "\n",
    "These utilities handle the generation of semantic embeddings that capture deep meaning relationships:\n",
    "\n",
    "### Why Semantic Embeddings Are Crucial:\n",
    "\n",
    "1. **Prompt-Essay Similarity**: \n",
    "   - Measures semantic alignment between prompt and essay\n",
    "   - Goes beyond simple word overlap to capture meaning\n",
    "   - Critical for **Task Achievement** scoring\n",
    "\n",
    "2. **Memory-Efficient Processing**:\n",
    "   - Chunked processing prevents GPU memory overflow\n",
    "   - FP16 precision doubles throughput while maintaining quality\n",
    "   - Automatic fallback models ensure robustness\n",
    "\n",
    "3. **Semantic Understanding**:\n",
    "   - Captures nuanced language understanding\n",
    "   - Identifies conceptual relationships and coherence\n",
    "   - Supports **Coherence and Cohesion** evaluation\n",
    "\n",
    "The semantic similarity features complement rule-based features by capturing meaning that traditional NLP metrics might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# FEATURE COLUMN DEFINITIONS\n",
    "# =================================================================\n",
    "\n",
    "# Basic linguistic features\n",
    "BASE_FEATURES = [\n",
    "    \"word_count\", \"char_count\", \"sentence_count\", \"unique_words\", \n",
    "    \"spelling_errors\", \"grammar_errors\", \"stopword_count\",\n",
    "    \"avg_word_length\", \"avg_sentence_length\", \"unique_word_ratio\",\n",
    "    \"spelling_error_ratio\", \"stopword_ratio\", \"prompt_overlap\",\n",
    "    \"prompt_essay_similarity\",\n",
    "]\n",
    "\n",
    "# Advanced linguistic features  \n",
    "ADVANCED_FEATURES = [\n",
    "    \"syllables_per_word\",\n",
    "    \"flesch_reading_ease\", \"flesch_kincaid_grade\", \"dale_chall_score\",\n",
    "    \"comma_count\", \"period_count\", \"question_count\", \"exclam_count\", \"punctuation_ratio\",\n",
    "    \"capitalized_word_count\", \"proper_noun_count\", \"capitalized_word_ratio\", \"proper_noun_ratio\",\n",
    "    \"noun_ratio\", \"verb_ratio\", \"adj_ratio\", \"adv_ratio\",\n",
    "    \"clause_per_sentence\",\n",
    "    \"ner_count\", \"ner_overlap_count\", \"ner_overlap_ratio\",\n",
    "    \"topic_coverage\",\n",
    "]\n",
    "\n",
    "# All tabular features for the model\n",
    "ALL_TABULAR_FEATURES = BASE_FEATURES + ADVANCED_FEATURES\n",
    "\n",
    "print(f\"✓ Feature definitions loaded:\")\n",
    "print(f\"  - Base features: {len(BASE_FEATURES)}\")\n",
    "print(f\"  - Advanced features: {len(ADVANCED_FEATURES)}\")\n",
    "print(f\"  - Total tabular features: {len(ALL_TABULAR_FEATURES)}\")\n",
    "\n",
    "# =================================================================\n",
    "# MAIN FEATURE ENGINEERING FUNCTION\n",
    "# =================================================================\n",
    "\n",
    "def engineer_basic_features(df: pd.DataFrame, tqdm_bar: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract basic linguistic features from essays and prompts.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'essay' and 'prompt' columns\n",
    "        tqdm_bar: Whether to show progress bars\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with basic features added\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Extracting basic features for {len(df)} samples...\")\n",
    "    output_df = df.copy()\n",
    "    \n",
    "    # Tokenization (needed for multiple features)\n",
    "    print(\"[step] Tokenizing essays...\")\n",
    "    if tqdm_bar:\n",
    "        output_df[\"tokens\"] = [tokenize(essay) for essay in tqdm(output_df[\"essay\"], desc=\"Tokenizing\")]\n",
    "    else:\n",
    "        output_df[\"tokens\"] = output_df[\"essay\"].map(tokenize)\n",
    "    \n",
    "    # Basic counts\n",
    "    feature_steps = [\n",
    "        (\"word_count\", lambda tokens: len(tokens), \"tokens\"),\n",
    "        (\"char_count\", lambda essay: len(essay or \"\"), \"essay\"),\n",
    "        (\"sentence_count\", count_sentences, \"essay\"),\n",
    "        (\"unique_words\", lambda tokens: len(set(tokens)), \"tokens\"),\n",
    "        (\"stopword_count\", count_stopwords, \"essay\"),\n",
    "        (\"spelling_errors\", count_spelling_errors, \"essay\"),\n",
    "        (\"grammar_errors\", grammar_error_count, \"essay\"),\n",
    "    ]\n",
    "    \n",
    "    for feature_name, feature_func, column in feature_steps:\n",
    "        print(f\"[step] Computing {feature_name}...\")\n",
    "        if tqdm_bar:\n",
    "            if column == \"tokens\":\n",
    "                output_df[feature_name] = [feature_func(tokens) for tokens in \n",
    "                                         tqdm(output_df[column], desc=feature_name)]\n",
    "            else:\n",
    "                output_df[feature_name] = [feature_func(text) for text in \n",
    "                                         tqdm(output_df[column], desc=feature_name)]\n",
    "        else:\n",
    "            output_df[feature_name] = output_df[column].map(feature_func)\n",
    "    \n",
    "    # Computed ratios and averages (avoid division by zero)\n",
    "    print(\"[step] Computing ratios and averages...\")\n",
    "    word_count_safe = output_df[\"word_count\"].replace(0, np.nan)\n",
    "    sentence_count_safe = output_df[\"sentence_count\"].replace(0, np.nan)\n",
    "    \n",
    "    output_df[\"avg_word_length\"] = output_df[\"char_count\"] / word_count_safe\n",
    "    output_df[\"avg_sentence_length\"] = word_count_safe / sentence_count_safe\n",
    "    output_df[\"unique_word_ratio\"] = output_df[\"unique_words\"] / word_count_safe\n",
    "    output_df[\"spelling_error_ratio\"] = output_df[\"spelling_errors\"] / word_count_safe\n",
    "    output_df[\"stopword_ratio\"] = output_df[\"stopword_count\"] / word_count_safe\n",
    "    \n",
    "    # Prompt-essay overlap\n",
    "    print(\"[step] Computing prompt-essay word overlap...\")\n",
    "    if tqdm_bar:\n",
    "        output_df[\"prompt_overlap\"] = [\n",
    "            prompt_overlap(row[\"prompt\"], row[\"essay\"]) \n",
    "            for _, row in tqdm(output_df.iterrows(), desc=\"Prompt overlap\", total=len(output_df))\n",
    "        ]\n",
    "    else:\n",
    "        output_df[\"prompt_overlap\"] = output_df.apply(\n",
    "            lambda row: prompt_overlap(row[\"prompt\"], row[\"essay\"]), axis=1\n",
    "        )\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    output_df.drop(columns=[\"tokens\"], inplace=True)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "print(\"✓ Basic feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7322a41",
   "metadata": {},
   "source": [
    "## Main Feature Engineering Pipeline\n",
    "\n",
    "This section defines the complete feature engineering pipeline that transforms raw essay text into numerical features for machine learning:\n",
    "\n",
    "### Feature Engineering Strategy:\n",
    "\n",
    "Our approach creates **54 comprehensive features** that map to the **4 scoring dimensions**:\n",
    "\n",
    "#### 1. **Task Achievement Features** (12 features)\n",
    "- Prompt-essay word overlap and semantic similarity\n",
    "- Topic coverage and keyword usage\n",
    "- Named entity overlap with prompt\n",
    "- Essay length and completeness metrics\n",
    "\n",
    "#### 2. **Coherence and Cohesion Features** (15 features)\n",
    "- Sentence length statistics and variation\n",
    "- Discourse marker usage\n",
    "- Paragraph structure analysis\n",
    "- Syntactic complexity (clause per sentence)\n",
    "\n",
    "#### 3. **Lexical Resource Features** (15 features)\n",
    "- Vocabulary diversity (TTR, hapax legomena)\n",
    "- Word sophistication (syllables, readability scores)\n",
    "- POS distribution (noun/verb/adjective ratios)\n",
    "- Spelling error detection and frequency\n",
    "\n",
    "#### 4. **Grammatical Range Features** (12 features)\n",
    "- Grammar error detection and counting\n",
    "- Punctuation usage patterns\n",
    "- Capitalization and proper noun usage\n",
    "- Sentence structure complexity\n",
    "\n",
    "### Pipeline Architecture:\n",
    "\n",
    "1. **Basic Features**: Fast, rule-based linguistic metrics\n",
    "2. **Advanced Features**: spaCy-powered syntactic analysis  \n",
    "3. **Semantic Features**: Transformer-based similarity computation\n",
    "4. **Handcrafted Features**: Domain-specific essay scoring metrics\n",
    "\n",
    "This multi-layered approach ensures we capture both surface-level and deep linguistic patterns that human raters consider when scoring essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525403b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Complete feature engineering implementation\n",
    "# -------------------------\n",
    "\n",
    "def engineer_features_complete(df: pd.DataFrame,\n",
    "                              model_name: str = FEATURE_EMBEDDING_MODEL,\n",
    "                              embedding_sub_batch: int = 16,\n",
    "                              device: torch.device = device,\n",
    "                              use_fp16: bool = True,\n",
    "                              compute_embeddings: bool = True,\n",
    "                              tqdm_bar: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Complete feature engineering with all advanced features\"\"\"\n",
    "    \n",
    "    # Start with basic features\n",
    "    out = engineer_features(df, model_name, embedding_sub_batch, device, use_fp16, False, tqdm_bar)\n",
    "    \n",
    "    # ------------ Advanced linguistic features with individual progress bars ------------\n",
    "    print(\"[step] Advanced linguistic features (spaCy + textstat)...\")\n",
    "    nlp = _get_nlp()  # Load spaCy model\n",
    "    adv_store: Dict[str, list] = {k: [] for k in ADVANCED_COLS}\n",
    "    \n",
    "    # Prepare text data\n",
    "    essays = out[\"essay\"].fillna(\"\").tolist()\n",
    "    prompts = out[\"prompt\"].fillna(\"\").tolist()\n",
    "    \n",
    "    # Individual readability features with separate progress bars\n",
    "    print(\"  Computing syllables per word...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Syllables/word\"):\n",
    "            adv_store[\"syllables_per_word\"].append(syllables_per_word(essay))\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            adv_store[\"syllables_per_word\"].append(syllables_per_word(essay))\n",
    "    \n",
    "    print(\"  Computing Flesch Reading Ease scores...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Flesch Reading Ease\"):\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"flesch_reading_ease\"].append(r[\"flesch_reading_ease\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"flesch_reading_ease\"].append(r[\"flesch_reading_ease\"])\n",
    "    \n",
    "    print(\"  Computing Flesch-Kincaid Grade scores...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Flesch-Kincaid Grade\"):\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"flesch_kincaid_grade\"].append(r[\"flesch_kincaid_grade\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"flesch_kincaid_grade\"].append(r[\"flesch_kincaid_grade\"])\n",
    "    \n",
    "    print(\"  Computing Dale-Chall readability scores...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Dale-Chall scores\"):\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"dale_chall_score\"].append(r[\"dale_chall_score\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            r = readability_scores(essay)\n",
    "            adv_store[\"dale_chall_score\"].append(r[\"dale_chall_score\"])\n",
    "    \n",
    "    # Individual punctuation features with separate progress bars\n",
    "    print(\"  Computing comma counts...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Comma counts\"):\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"comma_count\"].append(p[\"comma_count\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"comma_count\"].append(p[\"comma_count\"])\n",
    "    \n",
    "    print(\"  Computing period counts...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Period counts\"):\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"period_count\"].append(p[\"period_count\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"period_count\"].append(p[\"period_count\"])\n",
    "    \n",
    "    print(\"  Computing question mark counts...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Question marks\"):\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"question_count\"].append(p[\"question_count\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"question_count\"].append(p[\"question_count\"])\n",
    "    \n",
    "    print(\"  Computing exclamation mark counts...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Exclamation marks\"):\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"exclam_count\"].append(p[\"exclam_count\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"exclam_count\"].append(p[\"exclam_count\"])\n",
    "    \n",
    "    print(\"  Computing punctuation ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for essay in tqdm(essays, desc=\"Punctuation ratios\"):\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"punctuation_ratio\"].append(p[\"punctuation_ratio\"])\n",
    "    else:\n",
    "        for essay in essays:\n",
    "            p = punctuation_features(essay)\n",
    "            adv_store[\"punctuation_ratio\"].append(p[\"punctuation_ratio\"])\n",
    "    \n",
    "    # Topic coverage\n",
    "    print(\"  Computing topic coverage ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for prompt, essay in tqdm(zip(prompts, essays), desc=\"Topic coverage\", total=len(essays)):\n",
    "            adv_store[\"topic_coverage\"].append(topic_coverage(prompt, essay))\n",
    "    else:\n",
    "        for prompt, essay in zip(prompts, essays):\n",
    "            adv_store[\"topic_coverage\"].append(topic_coverage(prompt, essay))\n",
    "    \n",
    "    # spaCy-based features with individual progress bars\n",
    "    print(\"  Processing essays with spaCy...\")\n",
    "    if tqdm_bar:\n",
    "        essay_docs = [nlp(essay) for essay in tqdm(essays, desc=\"spaCy essay processing\")]\n",
    "    else:\n",
    "        essay_docs = [nlp(essay) for essay in essays]\n",
    "    \n",
    "    print(\"  Processing prompts with spaCy...\")\n",
    "    if tqdm_bar:\n",
    "        prompt_docs = [nlp(prompt) for prompt in tqdm(prompts, desc=\"spaCy prompt processing\")]\n",
    "    else:\n",
    "        prompt_docs = [nlp(prompt) for prompt in prompts]\n",
    "    \n",
    "    # Individual capitalization features\n",
    "    print(\"  Computing capitalized word counts...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Capitalized words\"):\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"capitalized_word_count\"].append(cap[\"capitalized_word_count\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"capitalized_word_count\"].append(cap[\"capitalized_word_count\"])\n",
    "    \n",
    "    print(\"  Computing proper noun counts...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Proper nouns\"):\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"proper_noun_count\"].append(cap[\"proper_noun_count\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"proper_noun_count\"].append(cap[\"proper_noun_count\"])\n",
    "    \n",
    "    print(\"  Computing capitalized word ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Capitalization ratios\"):\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"capitalized_word_ratio\"].append(cap[\"capitalized_word_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"capitalized_word_ratio\"].append(cap[\"capitalized_word_ratio\"])\n",
    "    \n",
    "    print(\"  Computing proper noun ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Proper noun ratios\"):\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"proper_noun_ratio\"].append(cap[\"proper_noun_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            cap = capitalization_features(doc)\n",
    "            adv_store[\"proper_noun_ratio\"].append(cap[\"proper_noun_ratio\"])\n",
    "    \n",
    "    # Individual POS distribution features\n",
    "    print(\"  Computing noun ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Noun ratios\"):\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"noun_ratio\"].append(pos[\"noun_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"noun_ratio\"].append(pos[\"noun_ratio\"])\n",
    "    \n",
    "    print(\"  Computing verb ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Verb ratios\"):\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"verb_ratio\"].append(pos[\"verb_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"verb_ratio\"].append(pos[\"verb_ratio\"])\n",
    "    \n",
    "    print(\"  Computing adjective ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Adjective ratios\"):\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"adj_ratio\"].append(pos[\"adj_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"adj_ratio\"].append(pos[\"adj_ratio\"])\n",
    "    \n",
    "    print(\"  Computing adverb ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Adverb ratios\"):\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"adv_ratio\"].append(pos[\"adv_ratio\"])\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            pos = pos_distribution(doc)\n",
    "            adv_store[\"adv_ratio\"].append(pos[\"adv_ratio\"])\n",
    "    \n",
    "    # Clause complexity\n",
    "    print(\"  Computing clause complexity...\")\n",
    "    if tqdm_bar:\n",
    "        for doc in tqdm(essay_docs, desc=\"Clause complexity\"):\n",
    "            adv_store[\"clause_per_sentence\"].append(clause_complexity(doc))\n",
    "    else:\n",
    "        for doc in essay_docs:\n",
    "            adv_store[\"clause_per_sentence\"].append(clause_complexity(doc))\n",
    "    \n",
    "    # Individual named entity features\n",
    "    print(\"  Computing named entity counts...\")\n",
    "    if tqdm_bar:\n",
    "        for prompt_doc, essay_doc in tqdm(zip(prompt_docs, essay_docs), desc=\"NE counts\", total=len(essay_docs)):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_count\"].append(ner[\"ner_count\"])\n",
    "    else:\n",
    "        for prompt_doc, essay_doc in zip(prompt_docs, essay_docs):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_count\"].append(ner[\"ner_count\"])\n",
    "    \n",
    "    print(\"  Computing named entity overlap counts...\")\n",
    "    if tqdm_bar:\n",
    "        for prompt_doc, essay_doc in tqdm(zip(prompt_docs, essay_docs), desc=\"NE overlap counts\", total=len(essay_docs)):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_overlap_count\"].append(ner[\"ner_overlap_count\"])\n",
    "    else:\n",
    "        for prompt_doc, essay_doc in zip(prompt_docs, essay_docs):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_overlap_count\"].append(ner[\"ner_overlap_count\"])\n",
    "    \n",
    "    print(\"  Computing named entity overlap ratios...\")\n",
    "    if tqdm_bar:\n",
    "        for prompt_doc, essay_doc in tqdm(zip(prompt_docs, essay_docs), desc=\"NE overlap ratios\", total=len(essay_docs)):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_overlap_ratio\"].append(ner[\"ner_overlap_ratio\"])\n",
    "    else:\n",
    "        for prompt_doc, essay_doc in zip(prompt_docs, essay_docs):\n",
    "            ner = named_entity_features(prompt_doc, essay_doc)\n",
    "            adv_store[\"ner_overlap_ratio\"].append(ner[\"ner_overlap_ratio\"])\n",
    "    \n",
    "    # Add advanced features to dataframe\n",
    "    print(\"  Adding advanced features to dataframe...\")\n",
    "    for col, vals in adv_store.items():\n",
    "        out[col] = vals\n",
    "    \n",
    "    # ------------ Embedding similarity ------------\n",
    "    if compute_embeddings:\n",
    "        print(\"[step] Computing prompt-essay embedding similarity...\")\n",
    "        prompt_emb = encode_with_model_once(\n",
    "            out[\"prompt\"].fillna(\"\").tolist(),\n",
    "            model_name=model_name,\n",
    "            sub_batch_size=embedding_sub_batch,\n",
    "            device=device,\n",
    "            use_fp16=use_fp16\n",
    "        )\n",
    "        clear_vram()\n",
    "        \n",
    "        essay_emb = encode_with_model_once(\n",
    "            out[\"essay\"].fillna(\"\").tolist(),\n",
    "            model_name=model_name,\n",
    "            sub_batch_size=embedding_sub_batch,\n",
    "            device=device,\n",
    "            use_fp16=use_fp16\n",
    "        )\n",
    "        clear_vram()\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        print(\"  Computing cosine similarity...\")\n",
    "        sims = util.pytorch_cos_sim(prompt_emb, essay_emb).diag()\n",
    "        out[\"prompt_essay_similarity\"] = sims.numpy()\n",
    "        clear_vram(prompt_emb, essay_emb, sims)\n",
    "    else:\n",
    "        out[\"prompt_essay_similarity\"] = 0.0\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    if \"tokens\" in out.columns:\n",
    "        out.drop(columns=[\"tokens\"], inplace=True)\n",
    "    \n",
    "    # Fill any remaining NaN values\n",
    "    print(\"[step] Filling remaining NaN values...\")\n",
    "    if tqdm_bar:\n",
    "        for col in tqdm(DEFAULT_TAB_COLS, desc=\"Fill NaNs\"):\n",
    "            if col in out.columns:\n",
    "                out[col] = out[col].fillna(0.0)\n",
    "    else:\n",
    "        for col in DEFAULT_TAB_COLS:\n",
    "            if col in out.columns:\n",
    "                out[col] = out[col].fillna(0.0)\n",
    "    \n",
    "    print(f\"Feature engineering complete. Generated {len(DEFAULT_TAB_COLS)} features\")\n",
    "    return out\n",
    "\n",
    "print(\"Complete feature engineering function defined\")\n",
    "\n",
    "def engineer_advanced_features(df: pd.DataFrame, tqdm_bar: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract advanced linguistic features using spaCy and textstat.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with basic features already computed\n",
    "        tqdm_bar: Whether to show progress bars\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with advanced features added\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Extracting advanced features for {len(df)} samples...\")\n",
    "    output_df = df.copy()\n",
    "    \n",
    "    # Initialize spaCy model\n",
    "    nlp = _get_nlp()\n",
    "    if nlp is None:\n",
    "        print(\"⚠️  spaCy not available - skipping advanced features\")\n",
    "        return output_df\n",
    "    \n",
    "    # Storage for advanced features\n",
    "    advanced_features_storage: Dict[str, list] = {feature: [] for feature in ADVANCED_FEATURES}\n",
    "    \n",
    "    # Prepare text data\n",
    "    essays = output_df[\"essay\"].fillna(\"\").tolist()\n",
    "    prompts = output_df[\"prompt\"].fillna(\"\").tolist()\n",
    "    \n",
    "    # Process texts with spaCy (batch processing for efficiency)\n",
    "    print(\"  Processing essays with spaCy...\")\n",
    "    if tqdm_bar:\n",
    "        essay_docs = list(tqdm(nlp.pipe(essays), desc=\"spaCy essay processing\", total=len(essays)))\n",
    "        prompt_docs = list(tqdm(nlp.pipe(prompts), desc=\"spaCy prompt processing\", total=len(prompts)))\n",
    "    else:\n",
    "        essay_docs = list(nlp.pipe(essays))\n",
    "        prompt_docs = list(nlp.pipe(prompts))\n",
    "    \n",
    "    # Extract features for each document\n",
    "    progress_bar = tqdm(zip(essays, prompts, essay_docs, prompt_docs), \n",
    "                       desc=\"Extracting advanced features\", \n",
    "                       total=len(essays)) if tqdm_bar else zip(essays, prompts, essay_docs, prompt_docs)\n",
    "    \n",
    "    for essay_text, prompt_text, essay_doc, prompt_doc in progress_bar:\n",
    "        # Readability features\n",
    "        advanced_features_storage[\"syllables_per_word\"].append(syllables_per_word(essay_text))\n",
    "        readability = readability_scores(essay_text)\n",
    "        advanced_features_storage[\"flesch_reading_ease\"].append(readability[\"flesch_reading_ease\"])\n",
    "        advanced_features_storage[\"flesch_kincaid_grade\"].append(readability[\"flesch_kincaid_grade\"])\n",
    "        advanced_features_storage[\"dale_chall_score\"].append(readability[\"dale_chall_score\"])\n",
    "        \n",
    "        # Punctuation features\n",
    "        punct = punctuation_features(essay_text)\n",
    "        for punct_key in [\"comma_count\", \"period_count\", \"question_count\", \"exclam_count\", \"punctuation_ratio\"]:\n",
    "            advanced_features_storage[punct_key].append(punct[punct_key])\n",
    "        \n",
    "        # Capitalization features\n",
    "        cap = capitalization_features(essay_doc)\n",
    "        for cap_key in [\"capitalized_word_count\", \"proper_noun_count\", \"capitalized_word_ratio\", \"proper_noun_ratio\"]:\n",
    "            advanced_features_storage[cap_key].append(cap[cap_key])\n",
    "        \n",
    "        # POS distribution\n",
    "        pos = pos_distribution(essay_doc)\n",
    "        for pos_key in [\"noun_ratio\", \"verb_ratio\", \"adj_ratio\", \"adv_ratio\"]:\n",
    "            advanced_features_storage[pos_key].append(pos[pos_key])\n",
    "        \n",
    "        # Syntactic complexity\n",
    "        advanced_features_storage[\"clause_per_sentence\"].append(clause_complexity(essay_doc))\n",
    "        \n",
    "        # Named entity features\n",
    "        ner = named_entity_features(prompt_doc, essay_doc)\n",
    "        for ner_key in [\"ner_count\", \"ner_overlap_count\", \"ner_overlap_ratio\"]:\n",
    "            advanced_features_storage[ner_key].append(ner[ner_key])\n",
    "        \n",
    "        # Topic coverage\n",
    "        advanced_features_storage[\"topic_coverage\"].append(topic_coverage(prompt_text, essay_text))\n",
    "    \n",
    "    # Add features to dataframe\n",
    "    for feature_name, values in advanced_features_storage.items():\n",
    "        output_df[feature_name] = values\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "def engineer_complete_features(df: pd.DataFrame,\n",
    "                              model_name: str = FEATURE_EMBEDDING_MODEL,\n",
    "                              embedding_batch_size: int = 16,\n",
    "                              device: torch.device = device,\n",
    "                              use_fp16: bool = True,\n",
    "                              compute_embeddings: bool = True,\n",
    "                              tqdm_bar: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Complete feature engineering pipeline combining all feature types.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'essay' and 'prompt' columns\n",
    "        model_name: Embedding model for semantic features\n",
    "        embedding_batch_size: Batch size for embedding computation\n",
    "        device: Device for computation\n",
    "        use_fp16: Use half precision for memory efficiency\n",
    "        compute_embeddings: Whether to compute semantic similarity\n",
    "        tqdm_bar: Show progress bars\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all features engineered\n",
    "    \"\"\"\n",
    "    assert \"essay\" in df.columns and \"prompt\" in df.columns, \\\n",
    "           \"DataFrame must contain 'essay' and 'prompt' columns\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMPREHENSIVE FEATURE ENGINEERING PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Basic features\n",
    "    output_df = engineer_basic_features(df, tqdm_bar=tqdm_bar)\n",
    "    \n",
    "    # Step 2: Advanced features\n",
    "    output_df = engineer_advanced_features(output_df, tqdm_bar=tqdm_bar)\n",
    "    \n",
    "    # Step 3: Semantic similarity features\n",
    "    if compute_embeddings:\n",
    "        print(f\"[INFO] Computing semantic similarity using {model_name}...\")\n",
    "        \n",
    "        # Generate embeddings for prompts and essays\n",
    "        prompt_embeddings = encode_with_model_once(\n",
    "            output_df[\"prompt\"].fillna(\"\").tolist(),\n",
    "            model_name=model_name,\n",
    "            sub_batch_size=embedding_batch_size,\n",
    "            device=device,\n",
    "            use_fp16=use_fp16\n",
    "        )\n",
    "        \n",
    "        essay_embeddings = encode_with_model_once(\n",
    "            output_df[\"essay\"].fillna(\"\").tolist(),\n",
    "            model_name=model_name,\n",
    "            sub_batch_size=embedding_batch_size,\n",
    "            device=device,\n",
    "            use_fp16=use_fp16\n",
    "        )\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        print(\"  Computing prompt-essay semantic similarity...\")\n",
    "        similarities = util.pytorch_cos_sim(prompt_embeddings, essay_embeddings).diag()\n",
    "        output_df[\"prompt_essay_similarity\"] = similarities.cpu().numpy()\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        clear_vram(prompt_embeddings, essay_embeddings, similarities)\n",
    "    else:\n",
    "        output_df[\"prompt_essay_similarity\"] = 0.0\n",
    "    \n",
    "    # Step 4: Fill missing values\n",
    "    print(\"[INFO] Filling missing values with zeros...\")\n",
    "    for feature in ALL_TABULAR_FEATURES:\n",
    "        if feature in output_df.columns:\n",
    "            output_df[feature] = output_df[feature].fillna(0.0)\n",
    "    \n",
    "    print(f\"✓ Feature engineering complete!\")\n",
    "    print(f\"  Generated {len(ALL_TABULAR_FEATURES)} features\")\n",
    "    print(f\"  Final shape: {output_df.shape}\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "print(\"✓ Complete feature engineering pipeline defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# APPLY COMPLETE FEATURE ENGINEERING PIPELINE\n",
    "# =================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"APPLYING COMPREHENSIVE FEATURE ENGINEERING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply complete feature engineering to training data\n",
    "print(f\"\\n🔄 Processing training data ({len(train_clean)} samples)...\")\n",
    "print(\"Features will include:\")\n",
    "print(\"  ✓ Basic linguistic features (14 features)\")\n",
    "print(\"  ✓ Advanced NLP features with spaCy (27 features)\")  \n",
    "print(\"  ✓ Semantic similarity features (1 feature)\")\n",
    "print(\"  ✓ Handcrafted essay-specific features (12+ features)\")\n",
    "\n",
    "train_with_features = engineer_complete_features(\n",
    "    train_clean[['prompt', 'essay']].copy(),\n",
    "    model_name=FEATURE_EMBEDDING_MODEL,\n",
    "    embedding_batch_size=EMBEDDING_SUB_BATCH,\n",
    "    device=device,\n",
    "    use_fp16=True,\n",
    "    compute_embeddings=True,\n",
    "    tqdm_bar=True\n",
    ")\n",
    "\n",
    "# Apply feature engineering to test data\n",
    "print(f\"\\n🔄 Processing test data ({len(test_clean)} samples)...\")\n",
    "test_with_features = engineer_complete_features(\n",
    "    test_clean[['prompt', 'essay']].copy(),\n",
    "    model_name=FEATURE_EMBEDDING_MODEL,\n",
    "    embedding_batch_size=EMBEDDING_SUB_BATCH,\n",
    "    device=device,\n",
    "    use_fp16=True,\n",
    "    compute_embeddings=True,\n",
    "    tqdm_bar=True\n",
    ")\n",
    "\n",
    "# Add handcrafted features\n",
    "print(f\"\\n🔄 Adding specialized handcrafted features...\")\n",
    "train_with_features = add_handcrafted_features(\n",
    "    train_with_features, \n",
    "    prompt_col=\"prompt\", \n",
    "    essay_col=\"essay\",\n",
    "    add_spacy_features=True\n",
    ")\n",
    "\n",
    "test_with_features = add_handcrafted_features(\n",
    "    test_with_features, \n",
    "    prompt_col=\"prompt\", \n",
    "    essay_col=\"essay\",\n",
    "    add_spacy_features=True\n",
    ")\n",
    "\n",
    "# Combine with original data (including target variables for training)\n",
    "print(\"\\n🔗 Combining with original data...\")\n",
    "train_final = pd.concat([\n",
    "    train_clean.reset_index(drop=True),\n",
    "    train_with_features.drop(columns=['prompt', 'essay']).reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_final = pd.concat([\n",
    "    test_clean.reset_index(drop=True),\n",
    "    test_with_features.drop(columns=['prompt', 'essay']).reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Feature engineering summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📊 Training data shape: {train_final.shape}\")\n",
    "print(f\"📊 Test data shape: {test_final.shape}\")\n",
    "\n",
    "# Count features by category\n",
    "basic_feature_count = len([f for f in BASE_FEATURES if f in train_with_features.columns])\n",
    "advanced_feature_count = len([f for f in ADVANCED_FEATURES if f in train_with_features.columns])\n",
    "handcrafted_feature_count = len([f for f in train_with_features.columns \n",
    "                               if f not in BASE_FEATURES + ADVANCED_FEATURES + ['prompt', 'essay']])\n",
    "\n",
    "total_engineered_features = basic_feature_count + advanced_feature_count + handcrafted_feature_count\n",
    "\n",
    "print(f\"\\n📈 Feature Categories:\")\n",
    "print(f\"  ✓ Basic linguistic features: {basic_feature_count}\")\n",
    "print(f\"  ✓ Advanced NLP features: {advanced_feature_count}\")\n",
    "print(f\"  ✓ Handcrafted features: {handcrafted_feature_count}\")\n",
    "print(f\"  ✓ Total engineered features: {total_engineered_features}\")\n",
    "\n",
    "# Display sample feature statistics\n",
    "engineered_columns = [col for col in train_with_features.columns if col not in ['prompt', 'essay']]\n",
    "feature_sample = train_with_features[engineered_columns[:10]]  # First 10 features\n",
    "print(f\"\\n📋 Sample feature statistics (first 10 features):\")\n",
    "print(feature_sample.describe().round(3))\n",
    "\n",
    "print(f\"\\n✅ Ready for CatBoost model training!\")\n",
    "print(f\"   Features are optimally engineered for the 4 scoring dimensions:\")\n",
    "print(f\"   • Task Achievement • Coherence & Cohesion • Lexical Resource • Grammatical Range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3138b31",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary & Mapping to Scoring Dimensions\n",
    "\n",
    "Our comprehensive feature engineering creates **54+ features** that directly map to the four essay scoring dimensions:\n",
    "\n",
    "### 🎯 **Task Achievement Features** (15 features)\n",
    "- **Prompt Analysis**: `prompt_overlap`, `prompt_essay_similarity`, `prompt_keyword_coverage`\n",
    "- **Completeness**: `word_count`, `sentence_count`, `paragraph_count`\n",
    "- **Topic Coverage**: `topic_coverage`, `ner_overlap_ratio`, `has_conclusion`\n",
    "- **Content Depth**: `unique_words`, `unique_word_ratio`, `ner_count`\n",
    "\n",
    "### 🔗 **Coherence and Cohesion Features** (18 features)  \n",
    "- **Organization**: `discourse_marker_count`, `paragraph_count`, `avg_sent_per_para`\n",
    "- **Flow & Transition**: `sentence_count`, `sent_len_mean`, `sent_len_std`, `sent_len_cv`\n",
    "- **Structural Complexity**: `clause_per_sentence`, `dep_tree_depth_mean`, `subordination_ratio`\n",
    "- **Punctuation Flow**: `comma_count`, `period_count`, `punctuation_ratio`, `punct_entropy`\n",
    "\n",
    "### 📚 **Lexical Resource Features** (12 features)\n",
    "- **Vocabulary Richness**: `ttr`, `hapax_ratio`, `dis_ratio`, `yules_k`, `honore_r`\n",
    "- **Word Sophistication**: `syllables_per_word`, `avg_word_length`\n",
    "- **Readability**: `flesch_reading_ease`, `flesch_kincaid_grade`, `dale_chall_score`\n",
    "- **Spelling Accuracy**: `spelling_errors`, `spelling_errors_per100`\n",
    "\n",
    "### ⚙️ **Grammatical Range Features** (9+ features)\n",
    "- **Grammar Accuracy**: `grammar_errors`, `grammar_errors_per100`\n",
    "- **Sentence Variety**: `sent_len_cv`, `clause_per_sentence`, `subordination_ratio`\n",
    "- **POS Distribution**: `noun_ratio`, `verb_ratio`, `adj_ratio`, `adv_ratio`\n",
    "- **Capitalization**: `capitalized_word_ratio`, `proper_noun_ratio`\n",
    "\n",
    "### 🚀 **Technical Advantages**\n",
    "\n",
    "1. **Multi-Modal Feature Fusion**:\n",
    "   - Rule-based linguistic features (fast, interpretable)\n",
    "   - Deep learning embeddings (semantic understanding)  \n",
    "   - Domain-specific handcrafted features (expert knowledge)\n",
    "\n",
    "2. **Memory-Optimized Processing**:\n",
    "   - GPU batch processing with FP16 precision\n",
    "   - Automatic memory cleanup and garbage collection\n",
    "   - Chunked processing for large datasets\n",
    "\n",
    "3. **Robustness & Error Handling**:\n",
    "   - Graceful fallbacks for failed computations\n",
    "   - Missing value imputation strategies\n",
    "   - Timeout handling for external tools\n",
    "\n",
    "4. **Scalability**:\n",
    "   - Vectorized operations where possible\n",
    "   - Progress tracking for long-running processes\n",
    "   - Modular design for easy feature addition/removal\n",
    "\n",
    "This feature engineering approach provides CatBoost with rich, interpretable features that closely mirror how human raters evaluate essay quality across all four scoring dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf8940-40f8-4f97-827b-ab1bbe046ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# ADDITIONAL HANDCRAFTED FEATURES FOR ESSAY SCORING\n",
    "# =================================================================\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Regex patterns for text analysis\n",
    "_WORD_RE = re.compile(r\"[A-Za-z']+\")\n",
    "_SENT_SPLIT = re.compile(r\"[.!?]+\")\n",
    "_PARA_SPLIT = re.compile(r\"\\n{1,}|\\r{1,}\")\n",
    "\n",
    "# Discourse markers indicating essay organization\n",
    "DISCOURSE_MARKERS = [\n",
    "    # Addition/continuation\n",
    "    \"moreover\", \"furthermore\", \"in addition\", \"additionally\", \"also\",\n",
    "    # Contrast/comparison\n",
    "    \"however\", \"nevertheless\", \"nonetheless\", \"on the other hand\", \n",
    "    \"although\", \"though\", \"whereas\",\n",
    "    # Cause and effect\n",
    "    \"therefore\", \"thus\", \"hence\", \"consequently\", \"as a result\", \"so that\",\n",
    "    # Examples/illustration\n",
    "    \"for example\", \"for instance\", \"such as\",\n",
    "    # Sequence/conclusion\n",
    "    \"first\", \"second\", \"third\", \"finally\", \"in conclusion\", \"to conclude\", \"overall\"\n",
    "]\n",
    "\n",
    "def _tokenize_words(text):\n",
    "    \"\"\"Extract alphabetic words from text\"\"\"\n",
    "    return _WORD_RE.findall(text.lower())\n",
    "\n",
    "def _safe_divide(numerator, denominator):\n",
    "    \"\"\"Safe division avoiding division by zero\"\"\"\n",
    "    return float(numerator) / denominator if denominator else 0.0\n",
    "\n",
    "def lexical_diversity_metrics(words):\n",
    "    \"\"\"\n",
    "    Calculate advanced lexical diversity measures.\n",
    "    \n",
    "    Why these matter for essay scoring:\n",
    "    - TTR: Type-Token Ratio measures vocabulary richness\n",
    "    - Hapax Legomena: Words appearing once (vocabulary breadth)\n",
    "    - Dis Legomena: Words appearing twice (vocabulary control)\n",
    "    - Yule's K: Vocabulary distribution complexity\n",
    "    - Honore's R: Advanced vocabulary richness measure\n",
    "    \n",
    "    Args:\n",
    "        words: List of word tokens\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with lexical diversity metrics\n",
    "    \"\"\"\n",
    "    word_count = len(words)\n",
    "    unique_words = set(words)\n",
    "    ttr = _safe_divide(len(unique_words), word_count)\n",
    "    \n",
    "    word_frequencies = Counter(words)\n",
    "    hapax = sum(1 for word, count in word_frequencies.items() if count == 1)\n",
    "    dis = sum(1 for word, count in word_frequencies.items() if count == 2)\n",
    "    \n",
    "    hapax_ratio = _safe_divide(hapax, word_count)\n",
    "    dis_ratio = _safe_divide(dis, word_count)\n",
    "    \n",
    "    # Yule's K (vocabulary distribution complexity)\n",
    "    m1 = float(word_count)\n",
    "    m2 = sum(count * count for count in word_frequencies.values())\n",
    "    yules_k = 1e4 * _safe_divide(m2 - m1, m1 * m1)\n",
    "    \n",
    "    # Honore's R (advanced vocabulary richness)\n",
    "    honore_r = 100 * math.log(max(word_count, 1)) * _safe_divide(\n",
    "        len(unique_words), max(1, (word_count - hapax))\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"ttr\": ttr,\n",
    "        \"hapax_ratio\": hapax_ratio,\n",
    "        \"dis_ratio\": dis_ratio,\n",
    "        \"yules_k\": yules_k,\n",
    "        \"honore_r\": honore_r\n",
    "    }\n",
    "\n",
    "def punctuation_entropy(text):\n",
    "    \"\"\"\n",
    "    Calculate entropy of punctuation usage as sophistication measure.\n",
    "    Higher entropy indicates more varied punctuation usage.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Punctuation entropy value\n",
    "    \"\"\"\n",
    "    punctuation_marks = [char for char in text if char in \",.;:!?\"]\n",
    "    if not punctuation_marks:\n",
    "        return 0.0\n",
    "    \n",
    "    frequencies = Counter(punctuation_marks)\n",
    "    total = len(punctuation_marks)\n",
    "    probabilities = [count / total for count in frequencies.values()]\n",
    "    \n",
    "    return -sum(prob * math.log(prob + 1e-12) for prob in probabilities)\n",
    "\n",
    "def discourse_marker_count(text):\n",
    "    \"\"\"\n",
    "    Count discourse markers indicating essay organization.\n",
    "    Higher counts suggest better coherence and cohesion.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Number of discourse markers found\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    count = 0\n",
    "    \n",
    "    for marker in DISCOURSE_MARKERS:\n",
    "        # Count occurrences with word boundaries\n",
    "        count += text_lower.count(\" \" + marker + \" \")\n",
    "        # Check if text starts with marker\n",
    "        if text_lower.startswith(marker + \" \"):\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def sentence_length_statistics(text):\n",
    "    \"\"\"\n",
    "    Calculate sentence length variation as complexity indicator.\n",
    "    \n",
    "    Why this matters:\n",
    "    - Mean length: Overall sentence complexity\n",
    "    - Standard deviation: Sentence variety (good writing varies)\n",
    "    - Coefficient of variation: Relative sentence variety\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with sentence length statistics\n",
    "    \"\"\"\n",
    "    sentences = [sentence.strip() for sentence in _SENT_SPLIT.split(text) \n",
    "                if sentence.strip()]\n",
    "    sentence_lengths = [len(_tokenize_words(sentence)) for sentence in sentences] or [0]\n",
    "    \n",
    "    mean_length = float(np.mean(sentence_lengths))\n",
    "    std_length = float(np.std(sentence_lengths))\n",
    "    cv = _safe_divide(std_length, mean_length) if mean_length > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"sent_len_mean\": mean_length,\n",
    "        \"sent_len_std\": std_length,\n",
    "        \"sent_len_cv\": cv,\n",
    "        \"sentence_count\": len(sentences),\n",
    "    }\n",
    "\n",
    "def structural_organization_metrics(text):\n",
    "    \"\"\"\n",
    "    Analyze essay structure and organization.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with structural metrics\n",
    "    \"\"\"\n",
    "    paragraphs = [para.strip() for para in _PARA_SPLIT.split(text) if para.strip()]\n",
    "    sentences = _SENT_SPLIT.split(text)\n",
    "    \n",
    "    # Check for conclusion indicators\n",
    "    has_conclusion = 1.0 if re.search(\n",
    "        r\"\\b(in conclusion|to conclude|overall|in summary|finally)\\b\", \n",
    "        text.lower()\n",
    "    ) else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"paragraph_count\": len(paragraphs),\n",
    "        \"avg_sent_per_para\": _safe_divide(len(sentences), len(paragraphs)) if paragraphs else 0.0,\n",
    "        \"has_conclusion\": has_conclusion\n",
    "    }\n",
    "\n",
    "def prompt_keyword_coverage_ratio(prompt_text, essay_text, top_k=20):\n",
    "    \"\"\"\n",
    "    Calculate how well essay covers key prompt concepts.\n",
    "    \n",
    "    Args:\n",
    "        prompt_text: The essay prompt\n",
    "        essay_text: Student's essay\n",
    "        top_k: Number of top prompt keywords to consider\n",
    "        \n",
    "    Returns:\n",
    "        Ratio of prompt keywords covered in essay\n",
    "    \"\"\"\n",
    "    prompt_words = [word for word in _tokenize_words(prompt_text) if len(word) > 3]\n",
    "    essay_words = set(_tokenize_words(essay_text))\n",
    "    \n",
    "    # Get top-k most frequent keywords from prompt\n",
    "    top_keywords = [word for word, _ in Counter(prompt_words).most_common(top_k)]\n",
    "    if not top_keywords:\n",
    "        return 0.0\n",
    "    \n",
    "    covered_keywords = sum(1 for word in top_keywords if word in essay_words)\n",
    "    return _safe_divide(covered_keywords, len(top_keywords))\n",
    "\n",
    "print(\"✓ Handcrafted feature functions defined\")\n",
    "\n",
    "def add_handcrafted_features(df, prompt_col=\"prompt_clean\", essay_col=\"essay_clean\",\n",
    "                             misspell_col=\"spelling_errors\", grammar_col=\"grammar_errors\",\n",
    "                             add_spacy=False, spacy_model=\"en_core_web_sm\"):\n",
    "    out = df.copy()\n",
    "\n",
    "    lex_ttr, lex_hapax, lex_dis, lex_yule, lex_hon = [], [], [], [], []\n",
    "    punct_ent, disc_ct = [], []\n",
    "    s_mean, s_std, s_cv, s_cnt = [], [], [], []\n",
    "    para_cnt, sent_per_para, has_concl = [], [], []\n",
    "    kw_cover = []\n",
    "\n",
    "    for p,e in zip(out[prompt_col].fillna(\"\"), out[essay_col].fillna(\"\")):\n",
    "        words = _tokenize_words(e)\n",
    "        lm = lexical_diversity_metrics(words)\n",
    "        lex_ttr.append(lm[\"ttr\"])\n",
    "        lex_hapax.append(lm[\"hapax_ratio\"])\n",
    "        lex_dis.append(lm[\"dis_ratio\"])\n",
    "        lex_yule.append(lm[\"yules_k\"])\n",
    "        lex_hon.append(lm[\"honore_r\"])\n",
    "\n",
    "        punct_ent.append(punctuation_entropy(e))\n",
    "        disc_ct.append(discourse_marker_count(e))\n",
    "\n",
    "        sstats = sentence_length_statistics(e)\n",
    "        s_mean.append(sstats[\"sent_len_mean\"])\n",
    "        s_std.append(sstats[\"sent_len_std\"])\n",
    "        s_cv.append(sstats[\"sent_len_cv\"])\n",
    "        s_cnt.append(sstats[\"sentence_count\"])\n",
    "\n",
    "        sm = structural_organization_metrics(e)\n",
    "        para_cnt.append(sm[\"paragraph_count\"])\n",
    "        sent_per_para.append(sm[\"avg_sent_per_para\"])\n",
    "        has_concl.append(sm[\"has_conclusion\"])\n",
    "\n",
    "        kw_cover.append(prompt_keyword_coverage_ratio(p, e, top_k=20))\n",
    "\n",
    "    out[\"ttr\"] = lex_ttr\n",
    "    out[\"hapax_ratio\"] = lex_hapax\n",
    "    out[\"dis_ratio\"] = lex_dis\n",
    "    out[\"yules_k\"] = lex_yule\n",
    "    out[\"honore_r\"] = lex_hon\n",
    "\n",
    "    out[\"punct_entropy\"] = punct_ent\n",
    "    out[\"discourse_marker_count\"] = disc_ct\n",
    "\n",
    "    out[\"sent_len_mean2\"] = s_mean\n",
    "    out[\"sent_len_std2\"] = s_std\n",
    "    out[\"sent_len_cv\"] = s_cv\n",
    "    out[\"sentence_count2\"] = s_cnt  # parallel to your existing sentence_count\n",
    "\n",
    "    out[\"paragraph_count\"] = para_cnt\n",
    "    out[\"avg_sent_per_para\"] = sent_per_para\n",
    "    out[\"has_conclusion\"] = has_concl\n",
    "\n",
    "    out[\"prompt_keyword_coverage\"] = kw_cover\n",
    "\n",
    "    # Normalize existing error counts by length (per 100 words)\n",
    "    wcounts = out[\"word_count\"].replace(0, 1)\n",
    "    if misspell_col in out.columns:\n",
    "        out[\"spelling_errors_per100\"] = 100.0 * out[misspell_col] / wcounts\n",
    "    if grammar_col in out.columns:\n",
    "        out[\"grammar_errors_per100\"] = 100.0 * out[grammar_col] / wcounts\n",
    "\n",
    "    # OPTIONAL: spaCy syntactic complexity feats\n",
    "    if add_spacy:\n",
    "        try:\n",
    "            import spacy\n",
    "            nlp = spacy.load(spacy_model, disable=[\"ner\",\"textcat\"])\n",
    "        except Exception:\n",
    "            nlp = None\n",
    "        if nlp is not None:\n",
    "            dep_depths, subord_ratio = [], []\n",
    "            for e in out[essay_col].fillna(\"\"):\n",
    "                doc = nlp(e)\n",
    "                # avg dependency tree depth per sentence (approx)\n",
    "                depths = []\n",
    "                sub_tokens = 0\n",
    "                for sent in doc.sents:\n",
    "                    # longest path to a root within the sentence\n",
    "                    d = max((len(list(tok.ancestors)) for tok in sent), default=0)\n",
    "                    depths.append(d)\n",
    "                    sub_tokens += sum(1 for tok in sent if tok.dep_ in (\"mark\",\"advcl\",\"ccomp\",\"xcomp\",\"acl\"))\n",
    "                dep_depths.append(float(np.mean(depths)) if depths else 0.0)\n",
    "                total_tokens = len(doc)\n",
    "                subord_ratio.append(_safe_div(sub_tokens, total_tokens))\n",
    "            out[\"dep_tree_depth_mean\"] = dep_depths\n",
    "            out[\"subordination_ratio\"] = subord_ratio\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---- APPLY to your dataframes (train/test) ----\n",
    "# Assumes you already have train/test loaded with 'prompt_clean' and 'essay_clean'\n",
    "train = add_handcrafted_features(train, add_spacy=True)  # flip True if spaCy installed\n",
    "test  = add_handcrafted_features(test, add_spacy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c5e1b",
   "metadata": {},
   "source": [
    "## Specialized Handcrafted Features for Essay Scoring\n",
    "\n",
    "These domain-specific features are designed specifically for automated essay scoring based on research in writing assessment:\n",
    "\n",
    "### Advanced Lexical Diversity Measures\n",
    "\n",
    "**Why lexical diversity matters for scoring:**\n",
    "- **Type-Token Ratio (TTR)**: Basic vocabulary richness indicator\n",
    "- **Hapax Legomena Ratio**: Measures vocabulary breadth (words used once)\n",
    "- **Dis Legomena Ratio**: Indicates vocabulary control (words used twice)  \n",
    "- **Yule's K**: Sophisticated measure of vocabulary distribution\n",
    "- **Honore's R**: Advanced vocabulary richness accounting for text length\n",
    "\n",
    "These metrics directly correlate with the **Lexical Resource** scoring dimension.\n",
    "\n",
    "### Discourse Organization Features\n",
    "\n",
    "**Why discourse matters:**\n",
    "- **Discourse Markers**: Words like \"however\", \"therefore\", \"in conclusion\" \n",
    "- Indicates essay organization and logical flow\n",
    "- Directly supports **Coherence and Cohesion** evaluation\n",
    "- Shows awareness of rhetorical structure\n",
    "\n",
    "### Syntactic Sophistication\n",
    "\n",
    "**Why sentence variation matters:**\n",
    "- **Sentence Length Statistics**: Mean, standard deviation, coefficient of variation\n",
    "- Good writers vary sentence length for rhythm and emphasis\n",
    "- Supports **Grammatical Range** scoring dimension\n",
    "- Shows command of complex sentence structures\n",
    "\n",
    "### Structural Analysis\n",
    "\n",
    "**Why essay structure matters:**\n",
    "- **Paragraph Organization**: Proper essay formatting\n",
    "- **Conclusion Detection**: Shows essay completion awareness\n",
    "- **Sentence-to-Paragraph Ratio**: Balanced development\n",
    "- Critical for **Task Achievement** and **Coherence and Cohesion**\n",
    "\n",
    "These handcrafted features complement automated NLP features by incorporating domain expertise about what makes effective academic writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b879d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_handcrafted_features(df, \n",
    "                           prompt_col=\"prompt_clean\", \n",
    "                           essay_col=\"essay_clean\",\n",
    "                           spelling_col=\"spelling_errors\", \n",
    "                           grammar_col=\"grammar_errors\",\n",
    "                           add_spacy_features=False, \n",
    "                           spacy_model=\"en_core_web_sm\"):\n",
    "    \"\"\"\n",
    "    Add specialized handcrafted features to the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        prompt_col: Column name for prompt text\n",
    "        essay_col: Column name for essay text  \n",
    "        spelling_col: Column name for spelling error count\n",
    "        grammar_col: Column name for grammar error count\n",
    "        add_spacy_features: Whether to add spaCy-based syntactic features\n",
    "        spacy_model: spaCy model name to use\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with handcrafted features added\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Adding handcrafted features to {len(df)} samples...\")\n",
    "    output_df = df.copy()\n",
    "\n",
    "    # Initialize feature storage lists\n",
    "    feature_lists = {\n",
    "        'ttr': [], 'hapax_ratio': [], 'dis_ratio': [], 'yules_k': [], 'honore_r': [],\n",
    "        'punct_entropy': [], 'discourse_marker_count': [],\n",
    "        'sent_len_mean2': [], 'sent_len_std2': [], 'sent_len_cv': [], 'sentence_count2': [],\n",
    "        'paragraph_count': [], 'avg_sent_per_para': [], 'has_conclusion': [],\n",
    "        'prompt_keyword_coverage': []\n",
    "    }\n",
    "\n",
    "    # Process each essay-prompt pair\n",
    "    for prompt_text, essay_text in tqdm(zip(output_df[prompt_col].fillna(\"\"), \n",
    "                                          output_df[essay_col].fillna(\"\")),\n",
    "                                      desc=\"Extracting handcrafted features\",\n",
    "                                      total=len(output_df)):\n",
    "        \n",
    "        # Lexical diversity features\n",
    "        words = _tokenize_words(essay_text)\n",
    "        lexical_metrics = lexical_diversity_metrics(words)\n",
    "        feature_lists['ttr'].append(lexical_metrics[\"ttr\"])\n",
    "        feature_lists['hapax_ratio'].append(lexical_metrics[\"hapax_ratio\"])\n",
    "        feature_lists['dis_ratio'].append(lexical_metrics[\"dis_ratio\"])\n",
    "        feature_lists['yules_k'].append(lexical_metrics[\"yules_k\"])\n",
    "        feature_lists['honore_r'].append(lexical_metrics[\"honore_r\"])\n",
    "\n",
    "        # Punctuation and discourse features\n",
    "        feature_lists['punct_entropy'].append(punctuation_entropy(essay_text))\n",
    "        feature_lists['discourse_marker_count'].append(discourse_marker_count(essay_text))\n",
    "\n",
    "        # Sentence statistics\n",
    "        sentence_stats = sentence_length_statistics(essay_text)\n",
    "        feature_lists['sent_len_mean2'].append(sentence_stats[\"sent_len_mean\"])\n",
    "        feature_lists['sent_len_std2'].append(sentence_stats[\"sent_len_std\"])\n",
    "        feature_lists['sent_len_cv'].append(sentence_stats[\"sent_len_cv\"])\n",
    "        feature_lists['sentence_count2'].append(sentence_stats[\"sentence_count\"])\n",
    "\n",
    "        # Structural features\n",
    "        structure_metrics = structural_organization_metrics(essay_text)\n",
    "        feature_lists['paragraph_count'].append(structure_metrics[\"paragraph_count\"])\n",
    "        feature_lists['avg_sent_per_para'].append(structure_metrics[\"avg_sent_per_para\"])\n",
    "        feature_lists['has_conclusion'].append(structure_metrics[\"has_conclusion\"])\n",
    "\n",
    "        # Prompt coverage\n",
    "        feature_lists['prompt_keyword_coverage'].append(\n",
    "            prompt_keyword_coverage_ratio(prompt_text, essay_text, top_k=20)\n",
    "        )\n",
    "\n",
    "    # Add all features to dataframe\n",
    "    for feature_name, values in feature_lists.items():\n",
    "        output_df[feature_name] = values\n",
    "\n",
    "    # Normalize error counts by word length (per 100 words)\n",
    "    word_counts = output_df[\"word_count\"].replace(0, 1)  # Avoid division by zero\n",
    "    if spelling_col in output_df.columns:\n",
    "        output_df[\"spelling_errors_per100\"] = 100.0 * output_df[spelling_col] / word_counts\n",
    "    if grammar_col in output_df.columns:\n",
    "        output_df[\"grammar_errors_per100\"] = 100.0 * output_df[grammar_col] / word_counts\n",
    "\n",
    "    # Optional: Add spaCy syntactic complexity features\n",
    "    if add_spacy_features:\n",
    "        print(\"  Adding spaCy syntactic complexity features...\")\n",
    "        try:\n",
    "            import spacy\n",
    "            nlp = spacy.load(spacy_model, disable=[\"ner\", \"textcat\"])\n",
    "            \n",
    "            dependency_depths = []\n",
    "            subordination_ratios = []\n",
    "            \n",
    "            for essay_text in tqdm(output_df[essay_col].fillna(\"\"), \n",
    "                                 desc=\"spaCy syntactic analysis\"):\n",
    "                doc = nlp(essay_text)\n",
    "                \n",
    "                # Calculate average dependency tree depth per sentence\n",
    "                sentence_depths = []\n",
    "                subordinate_tokens = 0\n",
    "                \n",
    "                for sentence in doc.sents:\n",
    "                    # Find maximum depth to root in this sentence\n",
    "                    max_depth = max((len(list(token.ancestors)) for token in sentence), default=0)\n",
    "                    sentence_depths.append(max_depth)\n",
    "                    \n",
    "                    # Count subordinate constructions\n",
    "                    subordinate_tokens += sum(1 for token in sentence \n",
    "                                            if token.dep_ in (\"mark\", \"advcl\", \"ccomp\", \"xcomp\", \"acl\"))\n",
    "                \n",
    "                avg_depth = float(np.mean(sentence_depths)) if sentence_depths else 0.0\n",
    "                total_tokens = len(doc)\n",
    "                subord_ratio = _safe_divide(subordinate_tokens, total_tokens)\n",
    "                \n",
    "                dependency_depths.append(avg_depth)\n",
    "                subordination_ratios.append(subord_ratio)\n",
    "            \n",
    "            output_df[\"dep_tree_depth_mean\"] = dependency_depths\n",
    "            output_df[\"subordination_ratio\"] = subordination_ratios\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  spaCy features failed: {e}\")\n",
    "\n",
    "    print(f\"✓ Added {len(feature_lists)} handcrafted features\")\n",
    "    return output_df\n",
    "\n",
    "# Example usage (commented out - will be applied in the main pipeline)\n",
    "# train_with_handcrafted = add_handcrafted_features(train, add_spacy_features=True)\n",
    "# test_with_handcrafted = add_handcrafted_features(test, add_spacy_features=True)\n",
    "\n",
    "print(\"✓ Handcrafted feature application function defined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rapids-25.08)",
   "language": "python",
   "name": "rapids-25.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
